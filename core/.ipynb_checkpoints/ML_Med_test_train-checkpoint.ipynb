{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for medicine\n",
    "## Training/Testing Dataset - The Basics of Inference\n",
    "\n",
    "## Overview\n",
    "In this notebook we introduce the idea of 'training and testing' sets.\n",
    "By leaving out a part of the data you collect, you can learn *and* validate complex patterns in your data.\n",
    "This simple process becomes a major strength of ML by directly addressing how \"generalizable\" your results are to broader populations and/or how well your results track with the truth.\n",
    "\n",
    "## Background\n",
    "ML is all about finding patterns in our data.\n",
    "When we have a carefully controlled and measured experiment there are some pretty simple patterns that our data could take.\n",
    "But, in the clinical world, there are a lot of uncontrolled variables and messy measurements - patterns can show up that don't actually have anything to do with what you're studying.\n",
    "Experiments help isolate variables so we can see if they relate to each other, but experiments are tough in clinical settings.\n",
    "\n",
    "One way ML takes this into account is with the idea of \"training\" sets and \"testing\" sets.\n",
    "Basically, you take the whole dataset you collected, split it into two sets (not necessary equal), then learn the pattern in the \"training\" set and see how well that pattern shows up in your \"testing\" set.\n",
    "\n",
    "### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The big library for doing math + data in python\n",
    "import numpy as np\n",
    "\n",
    "# A big library that has a lot of useful functions for scientific use of python\n",
    "import scipy\n",
    "\n",
    "# The main library for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "# The main library used for statistics\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Libraries that let us use interactive widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive,interact, HBox, Layout,VBox\n",
    "\n",
    "# Misc stuff related to cleaning up code and displaying results in a pretty way\n",
    "from example_systems import *\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and data\n",
    "In a typical experiment you're trying to study something about a *population*.\n",
    "You then design careful controls and measurements, get an idea of how many 'samples' you need to collect to be able to confidently say there's an effect.\n",
    "Then, and only then, do you recruit your sample, collect your data, and analyse *all* of it.\n",
    "The statistics you do on your analysis try to give you the level of confidence you can have that what you found in  your sample is what's happening in the population.\n",
    "Here, you're *implicitly* making conclusions about how well your results reflect the population, or **generalize**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vs Testing Set\n",
    "ML typically relies on a very different approach.\n",
    "In ML, you collect your data and try to understand the limitations in the data you collected.\n",
    "You can then **split your dataset** into a 'training' set and a 'testing' set, with zero overlapping datapoints.\n",
    "The 'training' set is where you do your 'learning' -> let the algorithm of your choice find the patterns that it thinks are in your data.\n",
    "The 'testing' set is where you take the pattern you just learned and see how well it holds.\n",
    "\n",
    "It's basically doing a 'simulated' experiment where your data is the 'population' and you subsample the population (training set) so you can *explicitly* test how well your results hold in the population, you're explicitly testing the **generalization**.\n",
    "This simple concept addresses a common criticism of 'pattern matching': if you analyse your data as is you'll almost always find patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMENT\n",
    "\n",
    "subplot(211) average A1c of a population - to see if certain populatons have diabetes more often\n",
    "subplot(212) training/test block diagram!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006aff27c7cf4146897dd0221a7b751d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Relationship:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slope_widg = widgets.FloatSlider(description='Relationship:')\n",
    "display(slope_widg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Example of training testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1625f7b30e455a958330b25af59a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='show_truth'), Checkbox(value=False, description='show_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.random.uniform(-10,10,size=(100,1))\n",
    "def gen_data(noise=10,train_ratio=0.1,trial=1):\n",
    "    m=2.4\n",
    "    Y = m * X + np.random.normal(0,noise,size=X.shape)\n",
    "    \n",
    "    Xtr,Xte,Ytr,Yte = train_test_split(X,Y,test_size=1-train_ratio,random_state=trial)\n",
    "    \n",
    "    return Xtr, Xte, Ytr, Yte, m\n",
    "\n",
    "def gen_lin_Y(noise,train_ratio,trial,show_truth,show_tr,show_te,show_pred,show_model):\n",
    "    #Do our linear regression analysis \n",
    "    reg = LinearRegression(fit_intercept=False).fit(Xtr, Ytr)\n",
    "    reg.score(Xtr, Ytr)\n",
    "    Ypred = reg.predict(Xte)\n",
    "\n",
    "    slope_estimate = round(reg.coef_[0,0],4)\n",
    "    \n",
    "    if show_tr: plt.scatter(Xtr,Ytr,s=30,alpha=0.7,label='Training')\n",
    "    if show_te: plt.scatter(Xte,Yte,s=70,alpha=0.9,color='red',label='Test')\n",
    "    if show_pred: plt.scatter(Xte,Ypred,s=90, facecolors='none', edgecolors='r',alpha=0.7,label='Prediction')\n",
    "    if show_truth: plt.plot(X,m*X,'--',alpha=0.9,label='Truth',color='green')\n",
    "    if show_model: plt.plot(X,slope_estimate*X,alpha=0.3,linewidth=6,color='green',label='Model'); plt.text(0,-40,'Estimated slope: ' + str(slope_estimate),color='green')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.ylim((-50,50))\n",
    "    plt.xlim((-15,15))\n",
    "    plt.title('True slope = ' + str(m))\n",
    "    sns.despine()\n",
    "Xtr,Xte,Ytr,Yte,m = gen_data()\n",
    "#First we'll fix the data and just work with building up the plot\n",
    "#w = interactive(gen_lin_Y,noise=(0.0,10.0,0.1),train_ratio=(0.05,0.95,0.05),trial=(1,1000,1),show_truth=True,show_tr=False,show_te=False,show_model=False,show_pred=False)\n",
    "w = interactive(gen_lin_Y,noise=fixed(5.0),train_ratio=fixed(0.20),trial=fixed(1),show_truth=True,show_tr=False,show_te=False,show_model=False,show_pred=False)\n",
    "display(w)\n",
    "#controls = HBox(w.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
    "#output = w.children[-1]\n",
    "#VBox([controls, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd719c832674278ad01cdcf0f20fc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=10.0, description='noise', max=10.0), FloatSlider(value=0.1, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = interactive(gen_data,noise=(0.0,10.0,0.1),train_ratio=(0.05,0.95,0.05),trial=(1,1000,1))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you set the training size to 0.2, it runs the train/test split once.\n",
    "To get a better idea of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do an example!\n",
    "\n",
    "Let's revisit our example from the previous notebook: Diabetes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
